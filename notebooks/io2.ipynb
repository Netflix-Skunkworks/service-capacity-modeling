{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdd7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from service_capacity_modeling.hardware import shapes\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6152910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<service_capacity_modeling.hardware.HardwareShapes at 0x7f77a81594c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea7b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shape=aws from /home/jolynch/pg/service-capacity-modeling/service_capacity_modeling/hardware/profiles/shapes/aws\n",
      "Loading /home/jolynch/pg/service-capacity-modeling/service_capacity_modeling/hardware/profiles/pricing/aws/3yr-reserved.json\n",
      "25662.0\n",
      "{'annual_cost_per_gib': 1.5,\n",
      " 'annual_cost_per_read_io': [(32000.0, 0.78),\n",
      "                             (64000.0, 0.552),\n",
      "                             (160000.0, 0.384),\n",
      "                             (256000.0, 0.384)],\n",
      " 'annual_cost_per_write_io': [(32000.0, 0.78),\n",
      "                              (64000.0, 0.552),\n",
      "                              (160000.0, 0.384),\n",
      "                              (256000.0, 0.384)],\n",
      " 'compatible_families': [],\n",
      " 'lifecycle': <Lifecycle.alpha: 'alpha'>,\n",
      " 'max_scale_size_gib': 16384,\n",
      " 'name': 'io2',\n",
      " 'read_io_latency_ms': {'allow_simulate': False,\n",
      "                        'confidence': 0.9,\n",
      "                        'high': 1.2,\n",
      "                        'low': 0.5,\n",
      "                        'maximum_value': 2.0,\n",
      "                        'mid': 0.8,\n",
      "                        'minimum_value': None,\n",
      "                        'model_with': D(beta)},\n",
      " 'read_io_per_s': None,\n",
      " 'single_tenant': True,\n",
      " 'size_gib': 0,\n",
      " 'write_io_latency_ms': {'allow_simulate': False,\n",
      "                         'confidence': 0.9,\n",
      "                         'high': 2.0,\n",
      "                         'low': 0.9,\n",
      "                         'maximum_value': 4.0,\n",
      "                         'mid': 1.2,\n",
      "                         'minimum_value': None,\n",
      "                         'model_with': D(beta)},\n",
      " 'write_io_per_s': None}\n"
     ]
    }
   ],
   "source": [
    "d = shapes.hardware.regions['us-east-1'].drives['io2']\n",
    "de = d.copy()\n",
    "de.size_gib = 100\n",
    "de.read_io_per_s = 33000\n",
    "print(de.annual_cost)\n",
    "pprint(shapes.hardware.regions['us-east-1'].drives['io2'].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea637b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from service_capacity_modeling.interface import CapacityDesires\n",
    "from service_capacity_modeling.interface import FixedInterval, Interval\n",
    "from service_capacity_modeling.interface import QueryPattern, DataShape\n",
    "\n",
    "db_desires = CapacityDesires(\n",
    "    # This service is important to the business, not critical (tier 0)\n",
    "    service_tier=1,\n",
    "    query_pattern=QueryPattern(\n",
    "        # Not sure exactly how much QPS we will do, but we think around\n",
    "        # 10,000 reads and 10,000 writes per second.\n",
    "        estimated_read_per_second=Interval(\n",
    "            low=10, mid=100, high=1000, confidence=0.9\n",
    "        ),\n",
    "        estimated_write_per_second=Interval(\n",
    "            low=125000, mid=250000, high=500000, confidence=0.9\n",
    "        ),\n",
    "    ),\n",
    "    # Not sure how much data, but we think it'll be below 1 TiB\n",
    "    data_shape=DataShape(\n",
    "        estimated_state_size_gib=Interval(low=400000, mid=876000, high=1752000, confidence=0.9),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab22d142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'core_reference_ghz': 2.3,\n",
      " 'cpu_cores': {'confidence': 0.9,\n",
      "               'high': 2.0,\n",
      "               'low': 2.0,\n",
      "               'maximum_value': 2.0,\n",
      "               'mid': 2.0,\n",
      "               'minimum_value': 2.0},\n",
      " 'disk_gib': {'confidence': 0.9,\n",
      "              'high': 0.0,\n",
      "              'low': 0.0,\n",
      "              'maximum_value': 0.0,\n",
      "              'mid': 0.0,\n",
      "              'minimum_value': 0.0},\n",
      " 'mem_gib': {'confidence': 0.9,\n",
      "             'high': 24.0,\n",
      "             'low': 24.0,\n",
      "             'maximum_value': 24.0,\n",
      "             'mid': 24.0,\n",
      "             'minimum_value': 24.0},\n",
      " 'network_mbps': {'confidence': 0.9,\n",
      "                  'high': 0.0,\n",
      "                  'low': 0.0,\n",
      "                  'maximum_value': 0.0,\n",
      "                  'mid': 0.0,\n",
      "                  'minimum_value': 0.0},\n",
      " 'requirement_type': 'elasticsearch-master-zonal'}\n",
      "Our #1 choice is 6 zones of:\n",
      "{'annual_cost': 830.0,\n",
      " 'attached_drives': [],\n",
      " 'cluster_type': 'elasticsearch-master',\n",
      " 'count': 1,\n",
      " 'instance': {'annual_cost': 830.0,\n",
      "              'cpu': 4,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': None,\n",
      "              'name': 'r5.xlarge',\n",
      "              'net_mbps': 1000.0,\n",
      "              'ram_gib': 31.65}}\n",
      "{'annual_cost': 424333.49999999994,\n",
      " 'attached_drives': [{'annual_cost_per_gib': 0.96,\n",
      "                      'annual_cost_per_read_io': [(3000.0, 0.0),\n",
      "                                                  (16000.0, 0.06)],\n",
      "                      'annual_cost_per_write_io': [(3000.0, 0.0),\n",
      "                                                   (16000.0, 0.06)],\n",
      "                      'lifecycle': <Lifecycle.alpha: 'alpha'>,\n",
      "                      'max_scale_size_gib': 16384,\n",
      "                      'name': 'gp3',\n",
      "                      'read_io_latency_ms': {'confidence': 0.9,\n",
      "                                             'high': 1.8,\n",
      "                                             'low': 0.8,\n",
      "                                             'maximum_value': 10.0,\n",
      "                                             'mid': 1.05},\n",
      "                      'read_io_per_s': 200,\n",
      "                      'size_gib': 5461.333333333333,\n",
      "                      'write_io_latency_ms': {'confidence': 0.9,\n",
      "                                              'high': 4.0,\n",
      "                                              'low': 1.2,\n",
      "                                              'maximum_value': 20.0,\n",
      "                                              'mid': 2.0},\n",
      "                      'write_io_per_s': 600}],\n",
      " 'cluster_params': {'elasticsearch.copies': 3},\n",
      " 'cluster_type': 'elasticsearch-data',\n",
      " 'count': 75,\n",
      " 'instance': {'annual_cost': 414.9,\n",
      "              'cpu': 2,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': None,\n",
      "              'name': 'r5.large',\n",
      "              'net_mbps': 500.0,\n",
      "              'ram_gib': 15.71}}\n",
      "Our #2 choice is 6 zones of:\n",
      "{'annual_cost': 830.0,\n",
      " 'attached_drives': [],\n",
      " 'cluster_type': 'elasticsearch-master',\n",
      " 'count': 1,\n",
      " 'instance': {'annual_cost': 830.0,\n",
      "              'cpu': 4,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': None,\n",
      "              'name': 'r5.xlarge',\n",
      "              'net_mbps': 1000.0,\n",
      "              'ram_gib': 31.65}}\n",
      "{'annual_cost': 346346.0,\n",
      " 'attached_drives': [],\n",
      " 'cluster_params': {'elasticsearch.copies': 3},\n",
      " 'cluster_type': 'elasticsearch-data',\n",
      " 'count': 77,\n",
      " 'instance': {'annual_cost': 4498.0,\n",
      "              'cpu': 12,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': {'name': 'ephem',\n",
      "                        'read_io_latency_ms': {'confidence': 0.9,\n",
      "                                               'high': 0.16,\n",
      "                                               'low': 0.08,\n",
      "                                               'maximum_value': 2.0,\n",
      "                                               'mid': 0.12,\n",
      "                                               'minimum_value': 0.07},\n",
      "                        'size_gib': 6819},\n",
      "              'name': 'i3en.3xlarge',\n",
      "              'net_mbps': 12000.0,\n",
      "              'ram_gib': 95.54}}\n"
     ]
    }
   ],
   "source": [
    "from service_capacity_modeling.capacity_planner import planner\n",
    "from service_capacity_modeling.models.org import netflix\n",
    "from service_capacity_modeling.interface import Lifecycle\n",
    "import pprint\n",
    "\n",
    "# Load up the Netflix capacity models\n",
    "planner.register_group(netflix.models)\n",
    "\n",
    "cap_plan = planner.plan(\n",
    "    model_name=\"org.netflix.elasticsearch\",\n",
    "    region=\"us-east-1\",\n",
    "    desires=db_desires,\n",
    "    # Simulate the possible requirements 512 times\n",
    "    simulations=256,\n",
    "    # Request 3 diverse hardware families to be returned\n",
    "    num_results=5,\n",
    "    lifecycles=[Lifecycle.alpha, Lifecycle.stable],\n",
    "    instance_families=[\"i3en\", \"r5\"]\n",
    ")\n",
    "\n",
    "# The range of requirements in hardware resources (CPU, RAM, Disk, etc ...)\n",
    "requirements = cap_plan.requirements\n",
    "\n",
    "# The ordered list of least regretful choices for the requirement\n",
    "least_regret = cap_plan.least_regret\n",
    "\n",
    "# Show the range of requirements for a single zone\n",
    "pprint.pprint(requirements.zonal[0].dict(exclude_unset=True))\n",
    "\n",
    "# Show our least regretful choices of hardware in least regret order\n",
    "# So for example if we can buy the first set of computers we would prefer\n",
    "# to do that but we might not have availability in that family in which\n",
    "# case we'd buy the second one.\n",
    "for choice in range(len(least_regret)):\n",
    "    num_clusters = len(least_regret[choice].candidate_clusters.zonal)\n",
    "    print(f\"Our #{choice + 1} choice is {num_clusters} zones of:\")\n",
    "    seen = set()\n",
    "    zonal_clusters = least_regret[choice].candidate_clusters.zonal\n",
    "    for cluster in zonal_clusters:\n",
    "        if cluster.cluster_type in seen:\n",
    "            continue\n",
    "        seen.add(cluster.cluster_type)\n",
    "        pprint.pprint(cluster.dict(exclude_unset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e97ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'core_reference_ghz': 2.3,\n",
      " 'cpu_cores': {'confidence': 0.9,\n",
      "               'high': 2.0,\n",
      "               'low': 2.0,\n",
      "               'maximum_value': 2.0,\n",
      "               'mid': 2.0,\n",
      "               'minimum_value': 2.0},\n",
      " 'disk_gib': {'confidence': 0.9,\n",
      "              'high': 0.0,\n",
      "              'low': 0.0,\n",
      "              'maximum_value': 0.0,\n",
      "              'mid': 0.0,\n",
      "              'minimum_value': 0.0},\n",
      " 'mem_gib': {'confidence': 0.9,\n",
      "             'high': 24.0,\n",
      "             'low': 24.0,\n",
      "             'maximum_value': 24.0,\n",
      "             'mid': 24.0,\n",
      "             'minimum_value': 24.0},\n",
      " 'network_mbps': {'confidence': 0.9,\n",
      "                  'high': 0.0,\n",
      "                  'low': 0.0,\n",
      "                  'maximum_value': 0.0,\n",
      "                  'mid': 0.0,\n",
      "                  'minimum_value': 0.0},\n",
      " 'requirement_type': 'elasticsearch-master-zonal'}\n",
      "Our #1 choice is 6 zones of:\n",
      "{'annual_cost': 830.0,\n",
      " 'attached_drives': [],\n",
      " 'cluster_type': 'elasticsearch-master',\n",
      " 'count': 1,\n",
      " 'instance': {'annual_cost': 830.0,\n",
      "              'cpu': 4,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': None,\n",
      "              'name': 'r5.xlarge',\n",
      "              'net_mbps': 1000.0,\n",
      "              'ram_gib': 31.65}}\n",
      "{'annual_cost': 692317.5,\n",
      " 'attached_drives': [{'annual_cost_per_gib': 1.5,\n",
      "                      'annual_cost_per_read_io': [(32000.0, 0.78),\n",
      "                                                  (64000.0, 0.552),\n",
      "                                                  (160000.0, 0.384),\n",
      "                                                  (256000.0, 0.384)],\n",
      "                      'annual_cost_per_write_io': [(32000.0, 0.78),\n",
      "                                                   (64000.0, 0.552),\n",
      "                                                   (160000.0, 0.384),\n",
      "                                                   (256000.0, 0.384)],\n",
      "                      'lifecycle': <Lifecycle.alpha: 'alpha'>,\n",
      "                      'max_scale_size_gib': 16384,\n",
      "                      'name': 'io2',\n",
      "                      'read_io_latency_ms': {'confidence': 0.9,\n",
      "                                             'high': 1.2,\n",
      "                                             'low': 0.5,\n",
      "                                             'maximum_value': 2.0,\n",
      "                                             'mid': 0.8},\n",
      "                      'read_io_per_s': 200,\n",
      "                      'size_gib': 5461.333333333333,\n",
      "                      'write_io_latency_ms': {'confidence': 0.9,\n",
      "                                              'high': 2.0,\n",
      "                                              'low': 0.9,\n",
      "                                              'maximum_value': 4.0,\n",
      "                                              'mid': 1.2},\n",
      "                      'write_io_per_s': 600}],\n",
      " 'cluster_params': {'elasticsearch.copies': 3},\n",
      " 'cluster_type': 'elasticsearch-data',\n",
      " 'count': 75,\n",
      " 'instance': {'annual_cost': 414.9,\n",
      "              'cpu': 2,\n",
      "              'cpu_ghz': 3.1,\n",
      "              'drive': None,\n",
      "              'name': 'r5.large',\n",
      "              'net_mbps': 500.0,\n",
      "              'ram_gib': 15.71}}\n"
     ]
    }
   ],
   "source": [
    "from service_capacity_modeling.capacity_planner import planner\n",
    "from service_capacity_modeling.models.org import netflix\n",
    "from service_capacity_modeling.interface import Lifecycle\n",
    "import pprint\n",
    "\n",
    "# Load up the Netflix capacity models\n",
    "planner.register_group(netflix.models)\n",
    "\n",
    "cap_plan = planner.plan(\n",
    "    model_name=\"org.netflix.elasticsearch\",\n",
    "    region=\"us-east-1\",\n",
    "    desires=db_desires,\n",
    "    # Simulate the possible requirements 512 times\n",
    "    simulations=256,\n",
    "    # Request 3 diverse hardware families to be returned\n",
    "    num_results=5,\n",
    "    lifecycles=[Lifecycle.alpha, Lifecycle.stable],\n",
    "    instance_families=[\"r5\"],\n",
    "    drives=[\"io2\"]\n",
    ")\n",
    "\n",
    "# The range of requirements in hardware resources (CPU, RAM, Disk, etc ...)\n",
    "requirements = cap_plan.requirements\n",
    "\n",
    "# The ordered list of least regretful choices for the requirement\n",
    "least_regret = cap_plan.least_regret\n",
    "\n",
    "# Show the range of requirements for a single zone\n",
    "pprint.pprint(requirements.zonal[0].dict(exclude_unset=True))\n",
    "\n",
    "# Show our least regretful choices of hardware in least regret order\n",
    "# So for example if we can buy the first set of computers we would prefer\n",
    "# to do that but we might not have availability in that family in which\n",
    "# case we'd buy the second one.\n",
    "for choice in range(len(least_regret)):\n",
    "    num_clusters = len(least_regret[choice].candidate_clusters.zonal)\n",
    "    print(f\"Our #{choice + 1} choice is {num_clusters} zones of:\")\n",
    "    seen = set()\n",
    "    zonal_clusters = least_regret[choice].candidate_clusters.zonal\n",
    "    for cluster in zonal_clusters:\n",
    "        if cluster.cluster_type in seen:\n",
    "            continue\n",
    "        seen.add(cluster.cluster_type)\n",
    "        pprint.pprint(cluster.dict(exclude_unset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406b3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ec0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
